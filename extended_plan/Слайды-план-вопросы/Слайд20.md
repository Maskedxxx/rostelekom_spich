# **ЧАСТЬ 3: МЕТОДЫ УПРАВЛЕНИЯ И КОНТРОЛЬ ВЫВОДА**

## **Слайд 21: Парадигмальный Зазор: LLM vs Человек**

* **Заголовок:** LLM не Человек: Парадигмальный Зазор.  
* **Тезис (из мыслей):** LLM не знает о мире и не воспринимает слова как люди.  
* **Текст:** LLM — это математическая машина, которая предсказывает следующее слово на основе статистики, а не на основе истинного понимания мира, причины и следствия. Она оперирует семантическим пространством, а не здравым смыслом.  
* **Визуализация:** Сравнение: Мозг (Сеть) vs LLM (Трансформер).

## **Слайд 22: Простые Задачи Сложны для LLM**

* **Заголовок:** Задачи, которые вводят LLM в ступор.  
* **Тезис (из мыслей):** Задачи работы с текстом, которые просты людям, очень сложны LLM (аналогии, контекст).  
* **Текст:** Смысловые нюансы, глубокие аналогии, логика с несколькими шагами, требующая постоянной проверки фактов, — это области, где LLM может "галлюцинировать" или делать логические ошибки.  
* **Визуализация:** Пример промпта, который легко решает человек, но сложно LLM (например, цепочка сложных логических выводов).

## **Слайд 23: Принцип I: Задача по Смыслу**

* **Заголовок:** Принцип I: Давать Задачи по Смыслу (Где LLM сильна).  
* **Тезис (из мыслей):** Давать задачи по смыслу LLM (где она сильна).  
* **Текст:** LLM сильна в:  
  1. **Генерации:** Код, тексты, идеи.  
  2. **Трансформации:** Перевод, рефакторинг, суммаризация.  
  3. **Классификации:** Сортировка, извлечение сущностей.  
* **Визуализация:** Сферы компетенции LLM (Круговая диаграмма: Генерация, Трансформация, Классификация).

## **Слайд 24: Принцип II: Перенаправление на Инструменты (Tool Use)**

* **Заголовок:** Принцип II: Перенаправление на Инструменты (Tool Use/Agents).  
* **Тезис (из мыслей):** Перенаправлять на инструменты, проверять ответы.  
* **Текст:** LLM должна выступать в роли координатора: она понимает задачу, разбивает ее и делегирует фактическое исполнение внешним инструментам (калькулятор, компилятор, база данных).  
* **Визуализация:** Схема: LLM $\\to$ Вызов Инструмента (Code Interpreter, Database Query) $\\to$ Получение Результата.

## **Слайд 25: Управление Выводом: Системный Промпт**

* **Заголовок:** Техника 1: Системный Промпт (Persona & Constraints).  
* **Тезис (из мыслей):** Методы управления выводом: системный промпт.  
* **Текст:** Задание роли, тона и строгих ограничений перед основным запросом. Это самый базовый и важный способ "настроить" модель.  
  * Пример: "Ты — строгий TypeScript-ревьюер. Отвечай только в формате Markdown, без лишних слов."  
* **Визуализация:** Шаблон системного промпта.

## **Слайд 26: Управление Выводом: Output Format (JSON)**

* **Заголовок:** Техника 2: Строгий Формат Вывода (JSON/YAML).  
* **Тезис (из мыслей):** JSON, YAML, XML (для парсинга).  
* **Текст:** Для автоматизации LLM необходимо, чтобы ее вывод был машиночитаемым. Используйте response\_schema или укажите в промпте требование к JSON-схеме.  
  * Применение: Анализ логов, классификация задач, генерация конфигураций.  
* **Визуализация:** Пример JSON-схемы для LLM-вывода.

## **Слайд 27: Управление Выводом: Few-Shot/Chain-of-Thought**

* **Заголовок:** Техника 3: CoT и Few-Shot (Учим примерами).  
* **Тезис (из мыслей):** CoT, Few-Shot.  
* **Текст:**  
  * **Few-Shot:** Предоставление 1-3 примеров "запрос-ответ" для точного соответствия стилю/формату.  
  * **CoT (Chain-of-Thought):** Требование к LLM показать "мыслительный процесс" перед финальным ответом. Повышает точность сложных рассуждений.  
* **Визуализация:** Схема CoT: Запрос $\\to$ Мысли (Шаг 1, 2\) $\\to$ Ответ.

## **Слайд 28: Техника RAG (Retrieval-Augmented Generation)**

* **Заголовок:** RAG: Генерация, Обогащенная Поиском.  
* **Тезис (из мыслей):** RAG – основная техника для работы с документами/кодом/знаниями.  
* **Текст:** RAG позволяет "заземлить" LLM на актуальных, внутренних, или больших по объему данных, которые не помещаются в контекст. LLM получает факты и генерирует ответ на их основе.  
* **Визуализация:** Схема RAG: Векторная База $\\to$ Поиск $\\to$ LLM $\\to$ Ответ.

## **Слайд 29: RAG Глубже: Индексация и Векторизация**

* **Заголовок:** Как работает RAG: Индексация.  
* **Тезис (из мыслей):** Подготовка данных: чанки, векторизация.  
* **Текст:** Чтобы RAG работал, нужно разбить большие документы/код на "чанки" (куски) и перевести их в "векторы" (числовые представления смысла) с помощью Embedding-моделей. Векторы хранятся в Векторной Базе Данных.  
* **Визуализация:** Схема: Документ $\\to$ Чанкинг $\\to$ Векторизация.

## **Слайд 30: RAG Глубже: Оценка (RAG Evaluation)**

* **Заголовок:** Контроль Качества RAG.  
* **Тезис (из мыслей):** Свежие практики оценки RAG (Ragas, DeepEval, LangSmith).  
* **Текст:** Оценка RAG требует новых метрик:  
  * **Groundedness:** Насколько ответ основан на предоставленных документах.  
  * **Faithfulness:** Насколько ответ верен фактам.  
  * **Relevance:** Насколько ответ релевантен запросу.  
* **Визуализация:** Логотипы Ragas, DeepEval, LangSmith.

## **Слайд 31: Fine-Tuning: Когда и Зачем**

* **Заголовок:** Fine-Tuning: Тонкая Настройка Модели.  
* **Тезис (из мыслей):** Когда уместен fine-tuning: стиль/доменные зазоры/SLM-продукты.  
* **Текст:** Fine-Tuning (дообучение) нужно, когда:  
  1. Необходим специфический **стиль** или **тон** (например, корпоративный жаргон).  
  2. Модель должна работать с узким **доменным знанием**, где RAG не справляется (например, специфические API).  
  3. Вы создаете компактный **SLM-продукт** для конкретной задачи.

## **Слайд 32: Fine-Tuning: LoRA и Экономика**

* **Заголовок:** Экономика Fine-Tuning.  
* **Тезис (из мыслей):** Добавьте заметку про стоимость/поддержку датасетов.  
* **Текст:** Современный Fine-Tuning чаще всего использует метод **LoRA** (Low-Rank Adaptation), который дообучает только небольшую часть весов, делая процесс быстрым и дешевым. Основные затраты: **сбор, разметка и поддержка качественных датасетов**.  
* **Визуализация:** Схема LoRA (только небольшая часть весов меняется).

## **Слайд 33: Оценка Моделей: Базовые Метрики**

* **Заголовок:** Оценка Моделей: LLM Leaderboards.  
* **Тезис (из мыслей):** Базовые метрики.  
* **Текст:** Обзор базовых метрик: **MMLU** (Multitask Language Understanding), **GSM8K** (Math), **HumanEval** (Code). Они помогают быстро понять, где находится модель на общем рынке.  
* **Визуализация:** Скриншот LLM Leaderboard с ключевыми метриками.

## **Слайд 34: Оценка Моделей: Human Feedback (RLHF)**

* **Заголовок:** Оценка Моделей: Роль Человека.  
* **Тезис (из мыслей):** RLHF.  
* **Текст:** **Reinforcement Learning from Human Feedback (RLHF):** Самая важная часть. LLM обучается на предпочтениях человека. Вывод: если модель звучит естественно, это заслуга RLHF, а не только архитектуры.

## **Слайд 35: Принцип MCO (Model Cost Optimization)**

* **Заголовок:** Оптимизация Затрат на Модели (MCO).  
* **Тезис (из мыслей):** Контроль токенов/длина промпта/чанкинг.  
* **Текст:** Всегда следите за:  
  1. **Длиной Промпта:** Сокращайте ввод, убирайте лишний контекст.  
  2. **Эффективностью RAG:** Убедитесь, что чанкинг не приводит к отправке слишком большого объема данных.  
  3. **Выбором Модели:** Используйте дешевые SLM для простых задач (MCO).

## **Слайд 36: Переход: От Использования к Агентам**

* **Заголовок:** Преддверие Агентов.  
* **Тезис (из мыслей):** Переход к агентам.  
* **Текст:** Мы научились управлять LLM. Следующий шаг — научить их работать автономно, самостоятельно принимать решения и вызывать инструменты для выполнения многошаговых задач (Agentic SDLC).