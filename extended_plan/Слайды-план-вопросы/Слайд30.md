# **ЧАСТЬ 4: ПРИМЕНЕНИЕ В SDLC И ВОПРОСЫ БЕЗОПАСНОСТИ**

## **Слайд 37: Введение в Агентный SDLC**

* **Заголовок:** LLM в SDLC: От Помощника к Агенту.  
* **Тезис:** LLM переходит от роли интеллектуального автокомплита к роли автономного участника процесса разработки, способного выполнить многошаговые задачи.  
* **Текст:** Мы начинаем видеть LLM не просто как кодогенератор, а как полноценного агента, который может: понять задачу, создать план, выполнить код, протестировать его и отправить на ревью.  
* **Визуализация:**

## **Слайд 38: Кейс 1: Автодокументация**

* **Заголовок:** Автодокументация (README и JSDoc/TypeDoc).  
* **Тезис:** LLM радикально снижает технический долг, связанный с документацией.  
* **Текст:**  
  * **JSDoc/TypeDoc:** Генерация описаний для функций, классов и методов на основе сигнатуры и логики.  
  * **README:** Создание полных, структурированных файлов README.md для проектов и модулей, включая описание, установку и примеры использования.  
* **Визуализация:** Сравнение: "Было (ручное)" vs "Стало (LLM-генерируемое)".

## **Слайд 39: Кейс 2: Генерация Тестов к Legacy-коду**

* **Заголовок:** Покрытие Legacy-кода Тестами.  
* **Тезис:** LLM как инструмент для безопасного рефакторинга.  
* **Текст:** Модель анализирует сложный, непокрытый тестами код и генерирует наборы тестов (unit, integration), которые фиксируют текущее поведение. Это позволяет безопасно проводить рефакторинг и модернизацию.  
* **Визуализация:** Схема: Legacy Code $\\to$ LLM $\\to$ Test Suite (Jest/PyTest).

## **Слайд 40: Кейс 3: Стандартизированный Рефакторинг**

* **Заголовок:** Стандартизированный Рефакторинг через Агентов (CLI/MCP).  
* **Тезис:** LLM может обеспечить соблюдение стандартов и паттернов в масштабе всего кодовой базы.  
* **Текст:** Используя LLM, настроенную через Системный Промпт (например, на стиль AirBnB), можно создавать CLI-инструменты (агенты), которые автоматически применяют сложные правила рефакторинга, невозможные для стандартных линтеров.  
* **Визуализация:** Скриншот CLI-инструмента, который запрашивает: "Рефакторить код на основе паттерна \[X\]".

## **Слайд 41: Агентный SDLC: Сдвиг Парадигмы**

* **Заголовок:** От Написания Кода к Курированию Спецификаций.  
* **Тезис (из мыслей):** Поддержать тезисом о «агентном SDLC» из GitHub/индустрии 2025\.  
* **Текст:** В Agentic SDLC (термин 2024-2025) роль разработчика смещается:  
  * **Было:** Написание 80% кода, 20% спецификаций.  
  * **Стало:** Написание 20% спецификаций, 80% — курирование, проверка и доработка кода, сгенерированного агентами.  
* **Визуализация:** График сдвига ролей (Человек vs LLM-Агент).

## **Слайд 42: Применение в SDLC: Тестирование**

* **Заголовок:** LLM в Тестировании (Написание и Анализ).  
* **Тезис:** Тестирование: Написание тестов и анализ.  
* **Текст:** LLM не только пишет тесты, но и анализирует покрытие, предлагает пограничные случаи, которые могли быть упущены, и генерирует мок-данные для более реалистичного тестирования.  
* **Визуализация:**

## **Слайд 43: Применение в SDLC: Предварительное Ревью**

* **Заголовок:** LLM в Предварительном Ревью Кода.  
* **Тезис:** Предварительное Ревью кода: скорость и стандартизация.  
* **Текст:** LLM может выполнять "пред-ревью" (Pre-Commit/Pre-Merge checks):  
  * Проверка на соответствие code style и паттернам.  
  * Детектирование очевидных багов и потенциальных уязвимостей (до ручного ревью).  
  * Генерация саммари изменений для ревьюера.  
* **Визуализация:** Скриншот или схема, где LLM оставляет комментарии в PR.

## **Слайд 44: Применение в SDLC: Менеджмент и Анализ Затрат**

* **Заголовок:** Менеджмент и Анализ Затрат.  
* **Тезис:** LLM для приоритизации и оценки.  
* **Текст:**  
  * **Приоритизация:** Анализ фич и багов, кластеризация по приоритету и сложности.  
  * **Оценка:** Предварительный набросок плана работы и оценка трудозатрат на основе спецификации.  
  * **Саммари:** Суммаризация ежедневных отчетов, собраний и тикетов.

## **Слайд 45: Применение в SDLC: Проектирование**

* **Заголовок:** Проектирование (Предварительные Наброски и Планы).  
* **Тезис:** LLM как ментальный партнер для архитектора.  
* **Текст:** LLM помогает в начальных этапах:  
  * Генерация диаграмм (UML, Архитектурные) на основе текстового описания.  
  * Сравнение архитектурных решений (Microservices vs Monolith) с оценкой trade-offs.  
  * Составление первичных списков требований и технических задач.  
* **Визуализация:** Пример UML-диаграммы, сгенерированной из промпта.

## **Слайд 46: Применение в SDLC: Разработка с Агентами**

* **Заголовок:** Разработка с Агентами (End-to-End Tasks).  
* **Тезис:** Все виды задач, от фич до рефакторинга.  
* **Текст:** Самое сложное применение: автономные агенты, которые получают задачу ("Добавить поле 'email' в форму регистрации") и самостоятельно:  
  1. Идентифицируют необходимые файлы.  
  2. Модифицируют код и тесты.  
  3. Запускают тесты и исправляют ошибки.  
* **Визуализация:** Схема автономного цикла Agent $\\to$ Code $\\to$ Test $\\to$ Code (until pass).

## **Слайд 47: LLM-Безопасность: Новая Поверхность Атаки**

* **Заголовок:** Безопасность и Комплаенс: LLM-Угрозы.  
* **Тезис:** Внедрение LLM создает новую, критическую поверхность для атак.  
* **Текст:** Основные риски связаны с манипуляцией моделью (инъекция) и неконтролируемым доступом к внутренним данным и системам (функции, инструменты, RAG).  
* **Визуализация:**

## **Слайд 48: OWASP Top-10 для LLM (2025)**

* **Заголовок:** База Угроз: OWASP Top-10 для LLM (2025).  
* **Тезис:** OWASP Top-10 для LLM — база угроз.  
* **Текст:** Ключевые угрозы:  
  1. **Prompt Injection (Инъекция Промпта).**  
  2. **Insecure Output Handling (Небезопасная Обработка Вывода).**  
  3. **Training Data Poisoning (Отравление Обучающих Данных).**  
  4. **Sensitive Information Disclosure (Раскрытие Конфиденциальной Информации).**  
* **Визуализация:** Список 4-5 ключевых пунктов из OWASP Top-10 LLM.

## **Слайд 49: Угроза I: Prompt Injection**

* **Заголовок:** Prompt Injection: Детект и Мониторинг.  
* **Тезис:** Prompt-injection детект/мониторинг (например, Microsoft Defender).  
* **Текст:**  
  * **Прямая Инъекция:** Манипуляция системным промптом через пользовательский ввод.  
  * **Косвенная Инъекция:** Внедрение вредоносного промпта в документы, которые LLM обрабатывает через RAG, заставляя ее атаковать себя или пользователя.  
  * **Митигация:** Использование специализированных детекторов и мониторинг подозрительного ввода.

## **Слайд 50: Угроза II: Раскрытие Данных и Комплаенс**

* **Заголовок:** Управление Рисками (NIST AI RMF).  
* **Тезис:** NIST AI RMF как рамка управления рисками.  
* **Текст:** Раскрытие конфиденциальной информации может произойти через контекстное окно (если в него попадут секреты) или через "запоминание" моделью чувствительных данных.  
  * **Комплаенс:** Использование фреймворков, таких как NIST AI Risk Management Framework (RMF), для систематической оценки и управления рисками, связанными с ИИ.

## **Слайд 51: Митигация и Защитные Меры**

* **Заголовок:** Защита LLM-Приложений.  
* **Тезис:** Ключевые инструменты защиты.  
* **Текст:**  
  1. **Sandboxing (Песочница):** Ограничение доступа агентов и LLM к внешним ресурсам и критическим API.  
  2. **Input/Output Filtering:** Фильтрация пользовательского ввода (для инъекций) и проверка вывода LLM перед его использованием.  
  3. **Zero-Tolerance RAG:** Максимальное ограничение доступа LLM к чувствительным RAG-источникам (Принцип Наименьших Привилегий).  
* **Визуализация:** Схема архитектуры с точками контроля (фильтры ввода/вывода, песочница).

## **Слайд 52: Переход: Ключевые Выводы**

* **Заголовок:** Резюме: Следующие Шаги.  
* **Тезис:** Переход к заключительной части.  
* **Текст:** Мы обсудили, как управлять LLM и как применять ее в SDLC. Теперь перейдем к финальным выводам и определим, с чего начать уже сегодня.