примечания к слайдам:
- В ## **Слайд 2: Общее Введение: Этапы Человечества** добавить что в новых технологиях происходит одна и таже цикличность:
Дорого/работает так себе/доступно только ограниченному кругу лиц специалистов экспертов --> удешевление/работает более стабильно-лучше/доступ всем.
Привести пример (компьютеры, сотовые телфеоны, интернет, ПО, и так далее). Обьяснить что с ИИ будет то же самое, это не будет исключением.

- В ## **Слайд 3: Ускорение Процессов в IT** Добавить: все упрощается и уходит в абстракции, ничего не будет усложняться.

- В ## **Слайд 5: Аналогия II: Код как "Производство"** Добавить или изменить: может я ошибаюсь, но вроде Карпатый как то по другому Software 2.0 обьяснял, или я не так понял его обьяснение, надо уточнить этот момент

- В ## **Слайд 6: Новая Веха: Программирование Спецификациями** Добавить: не только каччественные инструкции но и контекст, и что контекст в LLM это новый RAM (здесь может по другому называться)
Так же добавить тезисы (очень понравились тезисы как снижается энтропия намерения от человека к машине) касающиеся Software 3.0 из статьи (Статья: https://arxiv.org/abs/2510.26493 / Ревью: https://arxiviq.substack.com/p/context-engineering-20-the-context / Код: https://github.com/GAIR-NLP/SII-CLI)

- В ## **Слайд 7: Эволюция ИИ в IT: График Прогресса** Добавить: как мне кажется добавить что таймлайн создания Transformera лег на идеальный таймлайн того что в мире просто накопились данные высокого качества и их очень много, и это как бы спелый плод оказался который был реализован на трансформерах

- В ## **Слайд 8: Нынешние Цифры Развития: Объем Кода** Сослаться: обязательно сослаться на руководителей бигтеха (google, openai, amazon и так далее, которые хвалятся что большая часть кода у них теперь через ИИ написано... Да пока это с костылями и так далее но все будет шлифоваться дальше и улучшаться)
Можно немного подстебать Рус бигтехи которые не разглядели этого потенциала, и наобарот стесняются говорить что у них ИИ код пишет в Прод, здесь причина Рус инженирия которая как мне кажется по философии должна быть сложной всегда, даже если есть возмоность упростить. Это не всегда плохо, просто она вот такая

- В ## **Слайд 11: Размеры Моделей: Градация** Добавить: что все чаще SML и LLM все чаще используются в связке, где простые функции выполняет SML а сложные рассждения LLM

- В ## **Слайд 12: Вариант Инференса: Облако Вендоров** (а так же 13 и 14 слайдах) Добавить кратко списком vk.cs b минусы каждого выбора

- В сложных слайдах (## **Слайд 17, ## **Слайд 18:, 19, 20. Максимально просто обьяснить с простой визуализации, ни кто не любит техничку слушать)

- В ## **Слайд 21: Парадигмальный Зазор: LLM vs Человек** (Можно добавить забавный факт, что модель даже написав целую статью на ХАБР НИКОГДА не видит слова цифры буквы, она видит только цифры эмбедингов)))

- В ## **Слайд 22: Простые Задачи Сложны для LLM** (добавить забавный тест моделей который долго выполнял функцию того что модель умная: посчитать букву К в слове ыекгциуккнб А еще забавный тест был вопрос про свиные крылышки и про что больше 9.11 или 9.3)

- В ## **Слайд 25: Управление Выводом: Системный Промпт** Добавить: насчет промпта можно тоже добавить забавные факты о системный промптах Claude Grok Cursor то что они ОГРОМНЫ (10тысяч токенов и выше)))

- В ## **Слайд 27: Управление Выводом: Few-Shot/Chain-of-Thought** Добавить: что уже есть инструменты которые динамически создают "на лету" few-shot примеры и вставляют в промпт, так как эта техника очень мощная и самая популярная
Про CoT добавить что эта техника одна из самых старых и до сих пор дает большой буст к производительности ответов, (Можно указать что в самом начале когда LLM появились в 2022 зимой, тогда CoT еще не было и инженеры говорили "Дай время модели подумать", что подрузамевало указать модель думать шаг за шагом)

- В слайдах про RAG тоже не усложнять техничку, максимально просто, желательно коротко и с простым визуалом

- В ## **Слайд 31: Fine-Tuning: Когда и Зачем** ОБЯЗАТЕЛЬНО: сообщить что Fine-Tuning это последнее что требуется сделать с моделью, перед этим сначала только промпт инженирия, потом RAG + техники RAG, и только когда не помогает совсем ничего только тогда Fine-Tuning,
И то обязательно снять изначальные метрикки работы качества модели, так как неправильное Fine-Tuning может ухудшить модель (В простанароде Сорвать резьбу)

- ## **Слайд 32: Fine-Tuning: LoRA и Экономика**: про LoRa стоит упоминуть что это скорее всего будет "горячая" тема в следующем году, так как SML набирают обороты а этот метод дешев быстр и результативен. (Вставить факт что стартап Миры Муратти (Одна из звезд OpenAI), опубликовала статью о LoRa недавно)

- ## **Слайд 33: Оценка Моделей: Базовые Метрики**: Про оценки и метрики надо очень качественно рассказать, желательно кейсы кратко упоминуть, но опять же без глубокой технички, просто назвать метрики, в каких ситуациях именно эти метрики применяются и так далее

В # **ЧАСТЬ 4: ПРИМЕНЕНИЕ В SDLC И ВОПРОСЫ БЕЗОПАСНОСТИ** Добавить кейс: переписывание Legace кода на новые фреймворки и другие языки программирования

- Насчет темы агентов: надо сразу понятно обьяснить что такое агент: типа тот же LLM только который выбирает tools смотрите что получилось, анализирует овтетить или еще раз выполнить tool и так в цикле
