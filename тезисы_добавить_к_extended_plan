Часть 1: Введение и Контекст

1.1. Хук: "Новый Компилятор"
Добавить: 
- краткие примеры реализации Software 1.0, Software 2.0, Software 3.0

1.2 Движение истории: почему сейчас?
Добавить:
- Краткие примеры RNN
- Кратко обьясните на понятном примере что такое самовнимание
- Указать что как раз время (2017-2022) к этому времени как раз накопилось достаточно качетсвенный данных для LLM обучения тьрансформеров
(указать форумы Reddit, мессенджеры, форумы, wikipedia, stackOverflow и так далее). Указать что дообучение как раз проходит от метода RLHF что как
раз было на форумах где люди задавали вопросы и были качественные на них ответы отмеченные самими юзерами.

1.3. Нынешнее состояние (Статистика)
Добавить:
- Добавить статистику не только с зарубежных опросах использовани ИИ в разработке в компаниях, но привести примеры Российских компаний которые заявляют,
что их код все больше пишется ИИ или с большим примененим ИИ
- Указать что именно Copilot больше подходит для опытных разработчиках так как он =помогает писать итеративно, где юзер начинает писать функцию или класс,
а Copilot уже предлогает завершение или продолжение, эти небольшие итерации лучше отслеживаются и более контролируемы. Здесь Юзер сам задает темп и архитектуру, а Copilit
лишь помощник.
- Указать что у Юзеров у которых опыта поменьше они все более доверят писать проекты от начала и до конца с помощью мощных моделей ИИ (Claude 4.1 Opus, Grok 4, Cursor).
- Указать что даже если доверии к коду немного снизилась, но рост экспенциален и он не избежен.
- Указать что модели все больше совершенствуются не только в качестве написания кода, но и в общем целом, и каждое обновление исправляет
ошибки и  каждая итерация все лучше и лучше проходит в разработке с ИИ
- ПРивести пример что все технологии проходят схожие циклы (указать именно технологии в разработке (компиляторы, классический ML, сами компьютеры когда то комнату занимали)),
примести пример с технологиями которые тоже были скептически встречены и были с ошибками и дорогими но в итоге теперь они повсеместно и у каждого имеются (автомобиль, сотовый тедефон и так далее),
все циклично, и с ИИ будет тоже самое сомнений нет
- Указать что все больше классических инструментов адаптируются под ИИ (указать Redis, БД любые, системы мониторинга, и так далее)
- Компании понимают что если не сделать ставку на ИИ сейчас, то в будущем можно просто проиграть и какой бы крупной компания не была,
Привести пример с (Kodak, Blackbery и другие, они тоже были скептически настроены против новых технологий и в итоге их просто нет больше с нами, хотя они были лидерами №1 у себя в сегменте)


Часть 2: Карта Мира LLM и Реалии

2.1. Модели: Типы, Размеры, Производители

- Указать что закрутые модели в некоторых компаниях (особенно российских), просто запрещены по системе безопасности (привести примеры чувствительных таких компаний, где личные данные много и так далее)
- Указать что что в закрытых что в открытах доминирую так же гиганты бигтеха (google, meta, microsoft, openai),
указать что есть исключения mistral, qwen, deepseek как исключение
- Один из минусов открытыз моделей то что все механика деплоя их и контроля инференса лежит исключительно на компании, что в сою очередь
требует дополнительных инженеров и времени и фокуса, так же требует сразу закупать вычислительные ресурсы, что очень дорого в моменте,
+ в на примере России из-за санкций добыть "железо" не легко

2.3. Взаимозаменяемость
- Указать разработка с LLM должна обязательно содержать тесты, а так же актуальные метрики workflow по которым можно
понимать насколько модель справляется со своей задачей то есть оценка, и потом при дообучении модели или изменения промптов мы можем опять прогнать
модель получить метрику и понять модель улучшилась, деградировала и стагнирует.
- Желательно в каждой компании иметь собственный бенчмарк по которому мы мождем определять оценку модели (привести примеры некоторых кейсов с такой оценкой бенчмарка)

Часть 3: Практика для Разработчиков: "Как 
управлять LLM"

Интерфейсы: Copilots и CLI (5 мин) 
- Упоминуть обязательно что подходят CLI Copilots для onprem компаниям

3.2. Ключевой Урок: LLM — не Редактор
- Сказать про инсайд голюцинаций, что голюцинации именно в RAG происходят в 2 вариантах:
Когда контекста для ответа мало и наобарот когда контекста много и он шумный (например из 10 чанков релевантны 1)
- Поэтому важно качественно подставлять контекст в промпты, это очень важно, по этому context engineering не такая и шутка
- Инструменты помогают в этом (tools), модели не надо знать все данные которые требуется подставить в промпт, он может ивидеть в списке инструмент который вовзращает определенные данные по
аргументам которые tool может принять и LLM вызывает tool и передает точечные аргументы и получает нужный контекст или данные!
- ИНСАЙД: Дополнительное дообучение на небольших выборках также повышает склонность к галлюцинациям, по этому все LLM инженеры из силиконовой долины
рекомендуют использовать дообучение только когда все предыдущие методы не помогают (например промпт инженирия few-shot, tools не помогают)
- ИНСАЙД: Карпатый говорит что агенты пока еще не умны должным образом (но все щее в переди)
- Поэтому промпт «поиск‑замену» модель может сделать плохо так как она просто генерирует токен за токеном, здесь как раз надо использовать tool для такой задачи
- Так же упоминуть что сейчас паочти все модели что закрытые что локальные хорошо делают структурированный ответ в json (указываем схемы полей даже вложенных
, к полям делаем описание что за поле и зачем, через Literal строго ограничиваем выбор сущностей, и вуаяля, модель генерирует строго структурированный ответ в json
схеме где каждое поле семантичесик заполняется, это как семантические якоря о которых мы позже поговорим)

3.3. Управление Галлюцинациями и Стилем (ICL/Few-shots) (10 
мин)

- Про few-shot указать что в тех задачах где мы не знаем какие few-shot подставлять мы можем так же создать tool который будет динамически генерировать примеры и подставлять изв промпт (привести примеры кейсов)
- НАпомнить что few-shot xxthtpdsxfqyj можная техника, она очень сильно подсказывает все что угодно, хоть стиль ответа хоть последовательность действий, Указываем их в xlm тегах <>
- В промптах не должно быть взаимозаменяющих инструкций, иначе модель просто будет рандомно сама выбирать (пример привести)
- CoT так же помогает снизить голюцинации, Как говорят инженеры силиконовые, "Дайте время модели подумать", почему это работает это отдельный вебинар можем сделать где мы подробно можем погрузиться в эту технику
- RAG и цитирование источников тоже можные техники (примеры предоставить) Про RAG тоже отдельный вебинар


3.4. "Язык" для LLM: Структурированный промптинг (XML) (5 мин) 
- Указать что у openai sdk (что сейчас почти эталон в использовать LLM SDK) Мы можем через Pydantic настраивать структурированные ответы, Pydantic хорошо так как жестко валидирует и направляет модель для качественно или заданного workflow ответа
- Указать что для onprem решений структурированные ответы есть ка ку Ollama так и vLLm


3.5. УГЛУБЛЕНО: MCP (Протокол Контекста) (10 мин)

- Указать про MCP более понятным языком, привести простые примеры что MCP это как бы API для агентов,
то есть у нас есть данные с которыми может взаимодействовать агент, мы примерно понимаем какие инструменты можем создать для роаботой с данными, на примере ETL SQL,
мы можем создать разных иснтрументов методов, описать их и предоставить задеплоить вместе с данными на сервере, и предоставить агенты получать список инструментов, так же смотреть методы и контракты tools
и агент просто понимает что ему передать на MCP что бы получить нужные данные или выполнить действия (колендарь, запись и что угоднол!)

- Как и в случаи Claude Code CLI антропик опять выпистил фичу которая теперь стандарт для LLM (антопик красавчики)


3.6. "Мозг" для LLM: Агенты (5 мин)
- Указать что есть проблема, память контекста может переполниться если агент будет вызывать много инструментов. По работе с памятью это другой вебинар, но здесь есть решения. Работа с промптами и строго отслеживать токены в контексте это обязательно!


Часть 4: Low-code для Скорости и Прототипов (10 
минут) 
4.1. Low-code / No-code системы с LLM (n8n и др.)

- Указать что Lowcode лпатформы есть локальный, то есть можно развернуть в предприятии, подключить локальные модели и дать доступы не техническим спеуиалистам и показать как строить workflow пайплайны.

Часть 5: Стратегия Внедрения и Первые Шаги (15 
минут)
Цель: Дать реалистичный план внедрения и показать, куда двигаться. 
5.1. RAG vs. Fine-tuning (5 мин)

- Указать что рассказывал инженер OpenAI devday где он показывал worflow как подойти к fine-tuning, Сначала всегда промпты, потом few-shot, потом игра с гиперпараметрами и оценка, потом
только когда ничего не помогает fine-tune
- Не лезть в fine-tune пока не сняте метрики текущей модели, может проихойти регрес модели и если не отследить модель просто будет хуже работать

5.2. Управление Ожиданиями и "Low-Hanging Fruit" (10 мин)

- Генерация тестов и воспроизведение их в песочнице
- Рефакторинг и снижение технического долга, здесь важны тесты которые явно будут показывать снижение тех долга (примеры привести)




